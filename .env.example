# Default STT adapter to use (local, local_gpu, or openai)
# If not set, defaults to "local"
# Options:
#   local     - CPU-based Faster Whisper (int8 quantization)
#   local_gpu - GPU-based Faster Whisper (int8/float16, requires CUDA)
#   openai    - OpenAI Whisper API (requires API key)
PADC_ADAPTER=local

# For GPU support, you may need to set the library path
# Uncomment and adjust the path based on your Python version if needed:
# export LD_LIBRARY_PATH=/path/to/venv/lib/python3.12/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH

# Whisper model size for local/local-gpu adapters
# Options: tiny, base, small, medium, large, large-v2, large-v3
# Larger models are more accurate but slower
WHISPER_MODEL=base

# Audio buffer size in seconds (how much audio to keep in memory)
# Default: 30.0 seconds
# Increase for longer dictation sessions, decrease to save memory
PADC_BUFFER_SECONDS=30.0

# OpenAI API key for using the OpenAI adapter
# Copy this file to .env and add your actual API key
OPENAI_API_KEY=your_openai_api_key_here